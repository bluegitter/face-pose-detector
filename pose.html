<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>FaceMesh Liveness Detection</title>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
  <style>
    .input_video {
      transform: scaleX(-1);
      width: 240px;
      height: 240px;
      border-radius: 50%;
      object-fit: cover;
      aspect-ratio: 1 / 1;
      display: block;
      margin: 0 auto;
    }
    .video-wrapper {
      width: 400px;
      height: 400px;
      overflow: hidden;
      margin: 0 auto;
      text-align: center;
    }
    #timer {
      font-size: 16px;
      color: red;
      text-align: center;
      margin-top: 5px;
    }
  </style>
</head>
<body>
  <div class="video-wrapper">
    <h2 id="status">è¯·é¢å¯¹å±å¹•</h2>
    <video class="input_video" autoplay playsinline muted></video>
    <div id="timer">å‰©ä½™æ—¶é—´ï¼š30ç§’</div>
  </div>

  <script>
    const videoElement = document.querySelector('.input_video');
    const statusElement = document.getElementById('status');
    const timerElement = document.getElementById('timer');

    const challengeSequence = ["å¼ å˜´", "ç‚¹å¤´", "çœ¨çœ¼", "å‘å³è½¬å¤´"];
    let currentStep = 0;
    let verified = false;
    let lastPrintedAction = "";
    let remainingTime = 30;
    let timerInterval;

    function startTimer() {
      clearInterval(timerInterval);
      remainingTime = 30;
      timerElement.style.display = 'block';
      timerElement.textContent = `å‰©ä½™æ—¶é—´ï¼š${remainingTime}ç§’`;

      timerInterval = setInterval(() => {
        remainingTime--;
        timerElement.textContent = `å‰©ä½™æ—¶é—´ï¼š${remainingTime}ç§’`;
        if (remainingTime <= 0) {
          clearInterval(timerInterval);
          statusElement.textContent = "â›” éªŒè¯å¤±è´¥ï¼Œè¯·é‡è¯•ï¼";
          currentStep = 0;
          verified = false;
          startTimer(); // é‡å¯è®¡æ—¶å™¨
        }
      }, 1000);
    }

    startTimer();

    function detectMouthOpen(landmarks) {
      const upperLip = landmarks[13];
      const lowerLip = landmarks[14];
      const faceHeight = Math.abs(landmarks[10].y - landmarks[152].y);
      const mouthDist = Math.abs(upperLip.y - lowerLip.y);
      const ratio = mouthDist / faceHeight;
      return ratio > 0.08;
    }

    function detectEyeClosed(landmarks, left = true) {
      const p1 = left ? landmarks[159] : landmarks[386];
      const p2 = left ? landmarks[145] : landmarks[374];
      const p3 = left ? landmarks[33] : landmarks[263];
      const p4 = left ? landmarks[133] : landmarks[362];
      const vertical = Math.abs(p1.y - p2.y);
      const horizontal = Math.abs(p3.x - p4.x);
      const ear = vertical / horizontal;
      if (ear < 0.2)
        console.log("ear : ", ear)
      return ear < 0.1;
    }

    function estimatePose(landmarks) {
      const leftEye = landmarks[33];
      const rightEye = landmarks[263];
      const noseTip = landmarks[1];
      const chin = landmarks[152];

      const yawRad = Math.atan2(rightEye.z - leftEye.z, rightEye.x - leftEye.x);
      const yaw = yawRad * (180 / Math.PI);

      const dz = chin.z - noseTip.z;
      const dy = chin.y - noseTip.y;
      const pitchRad = Math.atan2(dz, dy);
      const pitch = pitchRad * (180 / Math.PI);

      const rollRad = Math.atan2(rightEye.y - leftEye.y, rightEye.x - leftEye.x);
      const roll = rollRad * (180 / Math.PI);

      let action = "ä¿æŒé™æ­¢";
      if (yaw > 20) action = "å‘å·¦è½¬å¤´";
      else if (yaw < -20) action = "å‘å³è½¬å¤´";
      else if (pitch > 25) action = "ä½å¤´";
      else if (pitch < 10) action = "æŠ¬å¤´";
      else if (roll > 20) action = "å‘å·¦å€¾æ–œ";
      else if (roll < -20) action = "å‘å³å€¾æ–œ";

      return { yaw, pitch, roll, action };
    }

    function checkPoseSequence(pose, mouthOpen, eyeClosed) {
      if (verified) return true;

      const currentChallenge = challengeSequence[currentStep];
      let matched = false;

      switch (currentChallenge) {
        case "å¼ å˜´":
          matched = mouthOpen;
          break;
        case "çœ¨çœ¼":
          matched = eyeClosed;
          break;
        case "ç‚¹å¤´":
          matched = pose.pitch > 25;
          break;
        case "æŠ¬å¤´":
          matched = pose.pitch < 10;
          break;
        case "å‘å·¦è½¬å¤´":
          matched = pose.yaw > 20;
          break;
        case "å‘å³è½¬å¤´":
          matched = pose.yaw < -20;
          break;
        case "å‘å³å€¾æ–œ":
          matched = pose.roll < -20;
          break;
        case "å‘å·¦å€¾æ–œ":
          matched = pose.roll > 20;
          break;
      }

      if (matched) {
        console.log(`âœ… å·²å®Œæˆï¼š${currentChallenge}`);
        currentStep++;
      }

      if (currentStep >= challengeSequence.length) {
        verified = true;
        clearInterval(timerInterval);
        timerElement.style.display = 'none';
        return true;
      }

      return false;
    }

    const faceMesh = new FaceMesh({
      locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`
    });
    faceMesh.setOptions({
      maxNumFaces: 1,
      refineLandmarks: true,
      minDetectionConfidence: 0.5,
      minTrackingConfidence: 0.5
    });

    faceMesh.onResults(results => {
      if (results.multiFaceLandmarks && results.multiFaceLandmarks.length > 0) {
        const landmarks = results.multiFaceLandmarks[0];
        const pose = estimatePose(landmarks);
        const mouthOpen = detectMouthOpen(landmarks);
        const bothEyesClosed = detectEyeClosed(landmarks, true) && detectEyeClosed(landmarks, false);

        const additionalStatus = `${mouthOpen ? 'ğŸ‘„å¼ å˜´' : ''}${bothEyesClosed ? ' ğŸ‘ï¸çœ¨çœ¼' : ''}`;
        const fullActionText = `${pose.action} ${additionalStatus}`;

        if (fullActionText !== lastPrintedAction) {
          console.log(fullActionText);
          lastPrintedAction = fullActionText;
        }

        const passed = checkPoseSequence(pose, mouthOpen, bothEyesClosed);

        if (passed) {
          statusElement.textContent = `âœ… éªŒè¯é€šè¿‡ ğŸ‰`;
        } else {
          statusElement.textContent = `æŒ‘æˆ˜ ${challengeSequence[currentStep]}ï½œå½“å‰ï¼š${pose.action} ${additionalStatus}`;
        }
      } else {
        statusElement.textContent = 'æœªæ£€æµ‹åˆ°äººè„¸';
      }
    });

    const camera = new Camera(videoElement, {
      onFrame: async () => await faceMesh.send({ image: videoElement }),
      width: 640,
      height: 480
    });
    camera.start();
  </script>
</body>
</html>
