<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>FaceMesh Liveness Detection</title>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
  <style>
    .input_video {
      transform: scaleX(-1);
      width: 240px;
      height: 240px;
      border-radius: 50%;
      object-fit: cover;
      aspect-ratio: 1 / 1;
      display: block;
      margin: 0 auto;
    }
    .video-wrapper {
      width: 400px;
      height: 400px;
      overflow: hidden;
      margin: 0 auto;
      text-align: center;
    }
    #timer {
      font-size: 16px;
      color: red;
      text-align: center;
      margin-top: 5px;
    }
  </style>
</head>
<body>
  <div class="video-wrapper">
    <h2 id="status">请面对屏幕</h2>
    <video class="input_video" autoplay playsinline muted></video>
    <div id="timer">剩余时间：30秒</div>
  </div>

  <script>
    const videoElement = document.querySelector('.input_video');
    const statusElement = document.getElementById('status');
    const timerElement = document.getElementById('timer');

    const challengeSequence = ["张嘴", "点头", "眨眼", "向右转头"];
    let currentStep = 0;
    let verified = false;
    let lastPrintedAction = "";
    let remainingTime = 30;
    let timerInterval;

    function startTimer() {
      clearInterval(timerInterval);
      remainingTime = 30;
      timerElement.style.display = 'block';
      timerElement.textContent = `剩余时间：${remainingTime}秒`;

      timerInterval = setInterval(() => {
        remainingTime--;
        timerElement.textContent = `剩余时间：${remainingTime}秒`;
        if (remainingTime <= 0) {
          clearInterval(timerInterval);
          statusElement.textContent = "⛔ 验证失败，请重试！";
          currentStep = 0;
          verified = false;
          startTimer(); // 重启计时器
        }
      }, 1000);
    }

    startTimer();

    function detectMouthOpen(landmarks) {
      const upperLip = landmarks[13];
      const lowerLip = landmarks[14];
      const faceHeight = Math.abs(landmarks[10].y - landmarks[152].y);
      const mouthDist = Math.abs(upperLip.y - lowerLip.y);
      const ratio = mouthDist / faceHeight;
      return ratio > 0.08;
    }

    function detectEyeClosed(landmarks, left = true) {
      const p1 = left ? landmarks[159] : landmarks[386];
      const p2 = left ? landmarks[145] : landmarks[374];
      const p3 = left ? landmarks[33] : landmarks[263];
      const p4 = left ? landmarks[133] : landmarks[362];
      const vertical = Math.abs(p1.y - p2.y);
      const horizontal = Math.abs(p3.x - p4.x);
      const ear = vertical / horizontal;
      if (ear < 0.2)
        console.log("ear : ", ear)
      return ear < 0.1;
    }

    function estimatePose(landmarks) {
      const leftEye = landmarks[33];
      const rightEye = landmarks[263];
      const noseTip = landmarks[1];
      const chin = landmarks[152];

      const yawRad = Math.atan2(rightEye.z - leftEye.z, rightEye.x - leftEye.x);
      const yaw = yawRad * (180 / Math.PI);

      const dz = chin.z - noseTip.z;
      const dy = chin.y - noseTip.y;
      const pitchRad = Math.atan2(dz, dy);
      const pitch = pitchRad * (180 / Math.PI);

      const rollRad = Math.atan2(rightEye.y - leftEye.y, rightEye.x - leftEye.x);
      const roll = rollRad * (180 / Math.PI);

      let action = "保持静止";
      if (yaw > 20) action = "向左转头";
      else if (yaw < -20) action = "向右转头";
      else if (pitch > 25) action = "低头";
      else if (pitch < 10) action = "抬头";
      else if (roll > 20) action = "向左倾斜";
      else if (roll < -20) action = "向右倾斜";

      return { yaw, pitch, roll, action };
    }

    function checkPoseSequence(pose, mouthOpen, eyeClosed) {
      if (verified) return true;

      const currentChallenge = challengeSequence[currentStep];
      let matched = false;

      switch (currentChallenge) {
        case "张嘴":
          matched = mouthOpen;
          break;
        case "眨眼":
          matched = eyeClosed;
          break;
        case "点头":
          matched = pose.pitch > 25;
          break;
        case "抬头":
          matched = pose.pitch < 10;
          break;
        case "向左转头":
          matched = pose.yaw > 20;
          break;
        case "向右转头":
          matched = pose.yaw < -20;
          break;
        case "向右倾斜":
          matched = pose.roll < -20;
          break;
        case "向左倾斜":
          matched = pose.roll > 20;
          break;
      }

      if (matched) {
        console.log(`✅ 已完成：${currentChallenge}`);
        currentStep++;
      }

      if (currentStep >= challengeSequence.length) {
        verified = true;
        clearInterval(timerInterval);
        timerElement.style.display = 'none';
        return true;
      }

      return false;
    }

    const faceMesh = new FaceMesh({
      locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`
    });
    faceMesh.setOptions({
      maxNumFaces: 1,
      refineLandmarks: true,
      minDetectionConfidence: 0.5,
      minTrackingConfidence: 0.5
    });

    faceMesh.onResults(results => {
      if (results.multiFaceLandmarks && results.multiFaceLandmarks.length > 0) {
        const landmarks = results.multiFaceLandmarks[0];
        const pose = estimatePose(landmarks);
        const mouthOpen = detectMouthOpen(landmarks);
        const bothEyesClosed = detectEyeClosed(landmarks, true) && detectEyeClosed(landmarks, false);

        const additionalStatus = `${mouthOpen ? '👄张嘴' : ''}${bothEyesClosed ? ' 👁️眨眼' : ''}`;
        const fullActionText = `${pose.action} ${additionalStatus}`;

        if (fullActionText !== lastPrintedAction) {
          console.log(fullActionText);
          lastPrintedAction = fullActionText;
        }

        const passed = checkPoseSequence(pose, mouthOpen, bothEyesClosed);

        if (passed) {
          statusElement.textContent = `✅ 验证通过 🎉`;
        } else {
          statusElement.textContent = `挑战 ${challengeSequence[currentStep]}｜当前：${pose.action} ${additionalStatus}`;
        }
      } else {
        statusElement.textContent = '未检测到人脸';
      }
    });

    const camera = new Camera(videoElement, {
      onFrame: async () => await faceMesh.send({ image: videoElement }),
      width: 640,
      height: 480
    });
    camera.start();
  </script>
</body>
</html>
